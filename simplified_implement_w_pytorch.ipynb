{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb840c6f-1199-419b-9a0a-22c7a90fcf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dependencies\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn,save,load\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "#use gpu if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c84cfa-b8c4-48d7-b025-a975ef12c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "train = datasets.MNIST(root=\"./data\", download=True, train=True, transform=ToTensor())\n",
    "dataset = DataLoader(train,32) #batches of 32 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679afa6c-da8f-4635-a42c-9f75a4d9be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # flattened 28x28 images\n",
    "hidden_size = 500 \n",
    "num_classes = 10 # numbers from 0 to 9 \n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ac191-c39b-464c-8693-93bfe2e68051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Classifier Neural Network\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageClassifier,self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "        nn.Conv2d(1,32,(3,3)),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32,64,(3,3)),\n",
    "        nn.ReLU(),        \n",
    "        nn.Conv2d(64,64,(3,3)),\n",
    "        nn.ReLU(),        \n",
    "        nn.Flatten(),\n",
    "        #input shape:64 final output from last conv2d * (28-6) since each convlution layer shaves off 2 rows/columns\n",
    "        #output shape is the number of classes (10, cause 10 digits)\n",
    "        nn.Linear(64*(28-6)*(28-6),10) \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da60024-ec57-4df9-9783-7ca6db703ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instance of the NN,loss,optimizer\n",
    "\n",
    "clf = ImageClassifier().to(device)\n",
    "opt= Adam(clf.parameters(),lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training flow \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in num_epochs: #train for 10 epochs\n",
    "        for batch in dataset: #looping through the dataset\n",
    "            X,y=batch\n",
    "            X,y= X.to(device), y.to(device)\n",
    "            yhat=clf(X)\n",
    "            loss=loss_fn(yhat,y)\n",
    "            \n",
    "            #Apply backprop\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            #print(f'epoch {epoch+1}, loss is {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697801af-6b1d-4a8c-852b-e322c41f892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b563a87-211e-4618-8c66-0fcce4bb9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_state.pt','wb') as f:\n",
    "    save(clf.state_dict(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c4294-e9ba-4b32-be24-0c32dce71d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open('model_state.pt','rb') as f:\n",
    "        clf.load_state_dict(load(f))\n",
    "\n",
    "img = Image.open('img_1.jpg')\n",
    "img_tensor= ToTensor()(img).unsqueeze(0).to(device)\n",
    "print(torch.argmax(clf(img_tensor)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
